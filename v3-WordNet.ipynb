{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer, LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.metrics import edit_distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🎃</td>\n",
       "      <td>jack-o-lantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>🎄</td>\n",
       "      <td>Christmas tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>🎆</td>\n",
       "      <td>fireworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>🎇</td>\n",
       "      <td>sparkler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🧨</td>\n",
       "      <td>firecracker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>☄️</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>☄</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>🔥</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>💧</td>\n",
       "      <td>droplet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>🌊</td>\n",
       "      <td>water wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation            Name\n",
       "0                 🎃  jack-o-lantern\n",
       "1                 🎄  Christmas tree\n",
       "2                 🎆       fireworks\n",
       "3                 🎇        sparkler\n",
       "4                 🧨     firecracker\n",
       "...             ...             ...\n",
       "4585             ☄️           comet\n",
       "4586              ☄           comet\n",
       "4587              🔥            fire\n",
       "4588              💧         droplet\n",
       "4589              🌊      water wave\n",
       "\n",
       "[4590 rows x 2 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_dataset = pd.read_csv(\"./emojis.csv\")\n",
    "emojis_dataset = emojis_dataset[[\"Representation\", \"Name\"]]\n",
    "emojis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sentence) -> list[str]:\n",
    "  sentence = sentence.lower()\n",
    "  clean_sent = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "  tokens = word_tokenize(clean_sent)\n",
    "  tokens = [t for t in tokens if t not in stop_words]\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Name</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🎃</td>\n",
       "      <td>jack-o-lantern</td>\n",
       "      <td>[jackolantern]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>🎄</td>\n",
       "      <td>Christmas tree</td>\n",
       "      <td>[christmas, tree]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>🎆</td>\n",
       "      <td>fireworks</td>\n",
       "      <td>[fireworks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>🎇</td>\n",
       "      <td>sparkler</td>\n",
       "      <td>[sparkler]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🧨</td>\n",
       "      <td>firecracker</td>\n",
       "      <td>[firecracker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>☄️</td>\n",
       "      <td>comet</td>\n",
       "      <td>[comet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>☄</td>\n",
       "      <td>comet</td>\n",
       "      <td>[comet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>🔥</td>\n",
       "      <td>fire</td>\n",
       "      <td>[fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>💧</td>\n",
       "      <td>droplet</td>\n",
       "      <td>[droplet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>🌊</td>\n",
       "      <td>water wave</td>\n",
       "      <td>[water, wave]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation            Name       cleaned_text\n",
       "0                 🎃  jack-o-lantern     [jackolantern]\n",
       "1                 🎄  Christmas tree  [christmas, tree]\n",
       "2                 🎆       fireworks        [fireworks]\n",
       "3                 🎇        sparkler         [sparkler]\n",
       "4                 🧨     firecracker      [firecracker]\n",
       "...             ...             ...                ...\n",
       "4585             ☄️           comet            [comet]\n",
       "4586              ☄           comet            [comet]\n",
       "4587              🔥            fire             [fire]\n",
       "4588              💧         droplet          [droplet]\n",
       "4589              🌊      water wave      [water, wave]\n",
       "\n",
       "[4590 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_dataset = emojis_dataset[[\"Representation\", \"Name\"]]\n",
    "emojis_dataset[\"cleaned_text\"] = emojis_dataset[\"Name\"].apply(pre_process)\n",
    "emojis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms(word) -> list[str]:\n",
    "    hypernyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            for lemma in hypernym.lemmas():\n",
    "                hypernyms.add(lemma.name())\n",
    "    return hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonym_words(wordx):\n",
    "    keep = []\n",
    "    synsets = wordnet.synsets(wordx, lang='eng')\n",
    "    for synset in synsets:\n",
    "        word = synset.name().split(\".\")[0]\n",
    "        if word not in keep:\n",
    "            keep.append(word)\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_matching_emoji(word, emoji_dataset, threshold=0.6):\n",
    "    best_emoji = None\n",
    "    best_similarity = 0\n",
    "\n",
    "    word_synsets = wordnet.synsets(word)\n",
    "\n",
    "    if not word_synsets:\n",
    "        return None, 0\n",
    "    \n",
    "    emoji_dict = {row[\"Representation\"]: row[\"cleaned_text\"] for _, row in emoji_dataset.iterrows()}\n",
    "    \n",
    "    for emoji, emoji_names in emoji_dict.items():\n",
    "        for emoji_name in emoji_names:\n",
    "            emoji_name_synsets = wordnet.synsets(emoji_name)\n",
    "\n",
    "            if not emoji_name_synsets:\n",
    "                continue\n",
    "\n",
    "            w_synset = word_synsets[0]\n",
    "            e_synset = emoji_name_synsets[0]\n",
    "\n",
    "            w_synset\n",
    "            e_synset\n",
    "\n",
    "            similarity = w_synset.path_similarity(e_synset)\n",
    "            if similarity and similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_emoji = emoji\n",
    "\n",
    "    return (best_emoji, best_similarity) if best_similarity >= threshold else (None, best_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_emoji(sentence, emoji_dataset, threshold = 0.6) -> tuple[str, dict]:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    modified_tokens = []\n",
    "    similarities = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        pre_processed_token = pre_process(token)\n",
    "\n",
    "        if not pre_processed_token:\n",
    "            modified_tokens.append(token)\n",
    "            continue\n",
    "\n",
    "        best_emoji, best_similarity = get_best_matching_emoji(pre_processed_token[0], emoji_dataset, threshold)\n",
    "\n",
    "        if not best_emoji:\n",
    "            synonyms = find_synonym_words(pre_processed_token[0])\n",
    "            for synonym in synonyms:\n",
    "                best_emoji, best_similarity = get_best_matching_emoji(synonym, emoji_dataset, threshold)\n",
    "                if best_emoji:\n",
    "                    break\n",
    "\n",
    "        if not best_emoji:\n",
    "            hypernyms = get_hypernyms(pre_processed_token[0])\n",
    "            for hypernym in hypernyms:\n",
    "                best_emoji, best_similarity = get_best_matching_emoji(hypernym, emoji_dataset, threshold)\n",
    "                if best_emoji:\n",
    "                    break\n",
    "        \n",
    "        if best_emoji:\n",
    "            modified_tokens.append(best_emoji)\n",
    "        else:\n",
    "            modified_tokens.append(token)\n",
    "        \n",
    "        similarities[token] = best_similarity\n",
    "\n",
    "    modified_sentence = \" \".join(modified_tokens)\n",
    "    \n",
    "    return modified_sentence, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I want pizza and a movie night.\n",
      "Modified Sentence: I 👧 🍕 and a 🎥 🌃 .\n",
      "Similarities: {'want': 1.0, 'pizza': 1.0, 'movie': 1.0, 'night': 1.0}\n",
      "\n",
      "Input: This is such a sad day.\n",
      "Modified Sentence: This is such a 😥 day .\n",
      "Similarities: {'sad': 1.0, 'day': 0.3333333333333333}\n",
      "\n",
      "Input: Happy birthday to you!\n",
      "Modified Sentence: Happy 🎂 to you !\n",
      "Similarities: {'Happy': 0.2, 'birthday': 1.0}\n",
      "\n",
      "Input: I need a vacation by the beach.\n",
      "Modified Sentence: I need a vacation by the 🏖️ .\n",
      "Similarities: {'need': 0.5, 'vacation': 0.25, 'beach': 1.0}\n",
      "\n",
      "Input: coffee\n",
      "Modified Sentence: 🍫\n",
      "Similarities: {'coffee': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"I want pizza and a movie night.\",\n",
    "    \"This is such a sad day.\",\n",
    "    \"Happy birthday to you!\",\n",
    "    \"I need a vacation by the beach.\",\n",
    "    \"coffee\"\n",
    "]\n",
    "\n",
    "\n",
    "for sent in test_sentences:\n",
    "    modified_sentence, similarity = replace_with_emoji(sent, emojis_dataset)\n",
    "    print(f\"Input: {sent}\")\n",
    "    print(f\"Modified Sentence: {modified_sentence}\")\n",
    "    print(f\"Similarities: {similarity}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
