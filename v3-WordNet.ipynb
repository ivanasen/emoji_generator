{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer, LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.metrics import edit_distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸƒ</td>\n",
       "      <td>jack-o-lantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ğŸ„</td>\n",
       "      <td>Christmas tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ğŸ†</td>\n",
       "      <td>fireworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‡</td>\n",
       "      <td>sparkler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ğŸ§¨</td>\n",
       "      <td>firecracker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>â˜„ï¸</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>â˜„</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>ğŸ’§</td>\n",
       "      <td>droplet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>ğŸŒŠ</td>\n",
       "      <td>water wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation            Name\n",
       "0                 ğŸƒ  jack-o-lantern\n",
       "1                 ğŸ„  Christmas tree\n",
       "2                 ğŸ†       fireworks\n",
       "3                 ğŸ‡        sparkler\n",
       "4                 ğŸ§¨     firecracker\n",
       "...             ...             ...\n",
       "4585             â˜„ï¸           comet\n",
       "4586              â˜„           comet\n",
       "4587              ğŸ”¥            fire\n",
       "4588              ğŸ’§         droplet\n",
       "4589              ğŸŒŠ      water wave\n",
       "\n",
       "[4590 rows x 2 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_dataset = pd.read_csv(\"./emojis.csv\")\n",
    "emojis_dataset = emojis_dataset[[\"Representation\", \"Name\"]]\n",
    "emojis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sentence) -> list[str]:\n",
    "  sentence = sentence.lower()\n",
    "  clean_sent = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "  tokens = word_tokenize(clean_sent)\n",
    "  tokens = [t for t in tokens if t not in stop_words]\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Name</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸƒ</td>\n",
       "      <td>jack-o-lantern</td>\n",
       "      <td>[jackolantern]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ğŸ„</td>\n",
       "      <td>Christmas tree</td>\n",
       "      <td>[christmas, tree]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ğŸ†</td>\n",
       "      <td>fireworks</td>\n",
       "      <td>[fireworks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‡</td>\n",
       "      <td>sparkler</td>\n",
       "      <td>[sparkler]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ğŸ§¨</td>\n",
       "      <td>firecracker</td>\n",
       "      <td>[firecracker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>â˜„ï¸</td>\n",
       "      <td>comet</td>\n",
       "      <td>[comet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>â˜„</td>\n",
       "      <td>comet</td>\n",
       "      <td>[comet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>fire</td>\n",
       "      <td>[fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>ğŸ’§</td>\n",
       "      <td>droplet</td>\n",
       "      <td>[droplet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>ğŸŒŠ</td>\n",
       "      <td>water wave</td>\n",
       "      <td>[water, wave]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation            Name       cleaned_text\n",
       "0                 ğŸƒ  jack-o-lantern     [jackolantern]\n",
       "1                 ğŸ„  Christmas tree  [christmas, tree]\n",
       "2                 ğŸ†       fireworks        [fireworks]\n",
       "3                 ğŸ‡        sparkler         [sparkler]\n",
       "4                 ğŸ§¨     firecracker      [firecracker]\n",
       "...             ...             ...                ...\n",
       "4585             â˜„ï¸           comet            [comet]\n",
       "4586              â˜„           comet            [comet]\n",
       "4587              ğŸ”¥            fire             [fire]\n",
       "4588              ğŸ’§         droplet          [droplet]\n",
       "4589              ğŸŒŠ      water wave      [water, wave]\n",
       "\n",
       "[4590 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_dataset = emojis_dataset[[\"Representation\", \"Name\"]]\n",
    "emojis_dataset[\"cleaned_text\"] = emojis_dataset[\"Name\"].apply(pre_process)\n",
    "emojis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms(word) -> list[str]:\n",
    "    hypernyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            for lemma in hypernym.lemmas():\n",
    "                hypernyms.add(lemma.name())\n",
    "    return hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonym_words(wordx):\n",
    "    keep = []\n",
    "    synsets = wordnet.synsets(wordx, lang='eng')\n",
    "    for synset in synsets:\n",
    "        word = synset.name().split(\".\")[0]\n",
    "        if word not in keep:\n",
    "            keep.append(word)\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_matching_emoji(word, emoji_dataset, threshold=0.6):\n",
    "    best_emoji = None\n",
    "    best_similarity = 0\n",
    "\n",
    "    word_synsets = wordnet.synsets(word)\n",
    "\n",
    "    if not word_synsets:\n",
    "        return None, 0\n",
    "    \n",
    "    emoji_dict = {row[\"Representation\"]: row[\"cleaned_text\"] for _, row in emoji_dataset.iterrows()}\n",
    "    \n",
    "    for emoji, emoji_names in emoji_dict.items():\n",
    "        for emoji_name in emoji_names:\n",
    "            emoji_name_synsets = wordnet.synsets(emoji_name)\n",
    "\n",
    "            if not emoji_name_synsets:\n",
    "                continue\n",
    "\n",
    "            w_synset = word_synsets[0]\n",
    "            e_synset = emoji_name_synsets[0]\n",
    "\n",
    "            w_synset\n",
    "            e_synset\n",
    "\n",
    "            similarity = w_synset.path_similarity(e_synset)\n",
    "            if similarity and similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_emoji = emoji\n",
    "\n",
    "    return (best_emoji, best_similarity) if best_similarity >= threshold else (None, best_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_emoji(sentence, emoji_dataset, threshold = 0.6) -> tuple[str, dict]:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    modified_tokens = []\n",
    "    similarities = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        pre_processed_token = pre_process(token)\n",
    "\n",
    "        if not pre_processed_token:\n",
    "            modified_tokens.append(token)\n",
    "            continue\n",
    "\n",
    "        best_emoji, best_similarity = get_best_matching_emoji(pre_processed_token[0], emoji_dataset, threshold)\n",
    "\n",
    "        if not best_emoji:\n",
    "            synonyms = find_synonym_words(pre_processed_token[0])\n",
    "            for synonym in synonyms:\n",
    "                best_emoji, best_similarity = get_best_matching_emoji(synonym, emoji_dataset, threshold)\n",
    "                if best_emoji:\n",
    "                    break\n",
    "\n",
    "        if not best_emoji:\n",
    "            hypernyms = get_hypernyms(pre_processed_token[0])\n",
    "            for hypernym in hypernyms:\n",
    "                best_emoji, best_similarity = get_best_matching_emoji(hypernym, emoji_dataset, threshold)\n",
    "                if best_emoji:\n",
    "                    break\n",
    "        \n",
    "        if best_emoji:\n",
    "            modified_tokens.append(best_emoji)\n",
    "        else:\n",
    "            modified_tokens.append(token)\n",
    "        \n",
    "        similarities[token] = best_similarity\n",
    "\n",
    "    modified_sentence = \" \".join(modified_tokens)\n",
    "    \n",
    "    return modified_sentence, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I want pizza and a movie night.\n",
      "Modified Sentence: I ğŸ‘§ ğŸ• and a ğŸ¥ ğŸŒƒ .\n",
      "Similarities: {'want': 1.0, 'pizza': 1.0, 'movie': 1.0, 'night': 1.0}\n",
      "\n",
      "Input: This is such a sad day.\n",
      "Modified Sentence: This is such a ğŸ˜¥ day .\n",
      "Similarities: {'sad': 1.0, 'day': 0.3333333333333333}\n",
      "\n",
      "Input: Happy birthday to you!\n",
      "Modified Sentence: Happy ğŸ‚ to you !\n",
      "Similarities: {'Happy': 0.2, 'birthday': 1.0}\n",
      "\n",
      "Input: I need a vacation by the beach.\n",
      "Modified Sentence: I need a vacation by the ğŸ–ï¸ .\n",
      "Similarities: {'need': 0.5, 'vacation': 0.25, 'beach': 1.0}\n",
      "\n",
      "Input: coffee\n",
      "Modified Sentence: ğŸ«\n",
      "Similarities: {'coffee': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"I want pizza and a movie night.\",\n",
    "    \"This is such a sad day.\",\n",
    "    \"Happy birthday to you!\",\n",
    "    \"I need a vacation by the beach.\",\n",
    "    \"coffee\"\n",
    "]\n",
    "\n",
    "\n",
    "for sent in test_sentences:\n",
    "    modified_sentence, similarity = replace_with_emoji(sent, emojis_dataset)\n",
    "    print(f\"Input: {sent}\")\n",
    "    print(f\"Modified Sentence: {modified_sentence}\")\n",
    "    print(f\"Similarities: {similarity}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
