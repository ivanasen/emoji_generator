{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/anapetrova/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸƒ</td>\n",
       "      <td>jack-o-lantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ğŸ„</td>\n",
       "      <td>Christmas tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ğŸ†</td>\n",
       "      <td>fireworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‡</td>\n",
       "      <td>sparkler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ğŸ§¨</td>\n",
       "      <td>firecracker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>â˜„ï¸</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>â˜„</td>\n",
       "      <td>comet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>ğŸ’§</td>\n",
       "      <td>droplet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>ğŸŒŠ</td>\n",
       "      <td>water wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation            Name\n",
       "0                 ğŸƒ  jack-o-lantern\n",
       "1                 ğŸ„  Christmas tree\n",
       "2                 ğŸ†       fireworks\n",
       "3                 ğŸ‡        sparkler\n",
       "4                 ğŸ§¨     firecracker\n",
       "...             ...             ...\n",
       "4585             â˜„ï¸           comet\n",
       "4586              â˜„           comet\n",
       "4587              ğŸ”¥            fire\n",
       "4588              ğŸ’§         droplet\n",
       "4589              ğŸŒŠ      water wave\n",
       "\n",
       "[4590 rows x 2 columns]"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_dataset = pd.read_csv(\"./emojis.csv\")\n",
    "emojis_dataset = emojis_dataset[[\"Representation\", \"Name\"]]\n",
    "emojis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sentence) -> list[str]:\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  sentence = sentence.lower()\n",
    "  clean_sent = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "  tokens = word_tokenize(clean_sent)\n",
    "  tokens = [t for t in tokens if t not in stop_words]\n",
    "  tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Name</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸƒ</td>\n",
       "      <td>jack-o-lantern</td>\n",
       "      <td>[jackolantern]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ğŸ„</td>\n",
       "      <td>Christmas tree</td>\n",
       "      <td>[christmas, tree]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ğŸ†</td>\n",
       "      <td>fireworks</td>\n",
       "      <td>[firework]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‡</td>\n",
       "      <td>sparkler</td>\n",
       "      <td>[sparkler]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ğŸ§¨</td>\n",
       "      <td>firecracker</td>\n",
       "      <td>[firecracker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>â˜„ï¸</td>\n",
       "      <td>comet</td>\n",
       "      <td>[comet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>â˜„</td>\n",
       "      <td>comet</td>\n",
       "      <td>[comet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>fire</td>\n",
       "      <td>[fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>ğŸ’§</td>\n",
       "      <td>droplet</td>\n",
       "      <td>[droplet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>ğŸŒŠ</td>\n",
       "      <td>water wave</td>\n",
       "      <td>[water, wave]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4590 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation            Name       cleaned_text\n",
       "0                 ğŸƒ  jack-o-lantern     [jackolantern]\n",
       "1                 ğŸ„  Christmas tree  [christmas, tree]\n",
       "2                 ğŸ†       fireworks         [firework]\n",
       "3                 ğŸ‡        sparkler         [sparkler]\n",
       "4                 ğŸ§¨     firecracker      [firecracker]\n",
       "...             ...             ...                ...\n",
       "4585             â˜„ï¸           comet            [comet]\n",
       "4586              â˜„           comet            [comet]\n",
       "4587              ğŸ”¥            fire             [fire]\n",
       "4588              ğŸ’§         droplet          [droplet]\n",
       "4589              ğŸŒŠ      water wave      [water, wave]\n",
       "\n",
       "[4590 rows x 3 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_dataset = emojis_dataset[[\"Representation\", \"Name\"]]\n",
    "emojis_dataset[\"cleaned_text\"] = emojis_dataset[\"Name\"].apply(pre_process)\n",
    "emojis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms(word, pos_tagged):\n",
    "    hypernyms = set()\n",
    "    for syn in wordnet.synsets(word, pos=pos_tagged):\n",
    "        for hypernym in syn.hypernyms():\n",
    "                hypernyms.add(hypernym)\n",
    "    return hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hypernym - Ğ´ÑƒĞ¼Ğ° Ñ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ, ÑÑŠÑÑ‚Ğ°Ğ²Ğ»ÑĞ²Ğ°Ñ‰Ğ° ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ, Ğ² ĞºĞ¾ÑÑ‚Ğ¾ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°Ñ‚ Ğ´ÑƒĞ¼Ğ¸Ñ‚Ğµ Ñ Ğ¿Ğ¾-ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ; ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ color Ğµ hypernym Ğ½Ğ° red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synonym_words(word, pos_tagged):\n",
    "    keep = []\n",
    "    returned = []\n",
    "    synsets = wordnet.synsets(word, pos=pos_tagged)\n",
    "    for synset in synsets:\n",
    "        synonym = synset.name().split(\".\")[0]\n",
    "        if synonym not in keep:\n",
    "            keep.append(synonym) #we are interested in the name of the synset\n",
    "            returned.append(synset)\n",
    "\n",
    "    return returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_exact_synset(emoji_name, emoji_synsets):\n",
    "    for synset in emoji_synsets:\n",
    "        if emoji_name in synset.lemma_names():\n",
    "            return synset\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\"Convert Penn Treebank POS tags to WordNet POS tags.\"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_matching_emoji(word_synset, emoji_dataset, threshold):\n",
    "    best_emoji = None\n",
    "    best_similarity = 0\n",
    "\n",
    "    if not word_synset:\n",
    "        return None, 0\n",
    "    \n",
    "    emoji_dict = {row[\"Representation\"]: row[\"cleaned_text\"] for _, row in emoji_dataset.iterrows()}\n",
    "    \n",
    "    for emoji, emoji_names in emoji_dict.items():\n",
    "        for emoji_name in emoji_names:\n",
    "            emoji_name_synsets = wordnet.synsets(emoji_name)\n",
    "\n",
    "            if not emoji_name_synsets:\n",
    "                continue\n",
    "\n",
    "            emoji_synset = get_emoji_exact_synset(emoji_name, emoji_name_synsets)\n",
    "            \n",
    "            if not emoji_synset:\n",
    "                continue\n",
    "            \n",
    "            similarity = word_synset.path_similarity(emoji_synset)\n",
    "            if similarity and similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_emoji = emoji\n",
    "\n",
    "    return (best_emoji, best_similarity) if best_similarity >= threshold else (None, best_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_emoji_wordnet(sentence, emoji_dataset, threshold = 0.6):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(tokens)\n",
    "    modified_tokens = []\n",
    "    similarities = {} \n",
    "\n",
    "    for token, tag in tagged_words:\n",
    "        pre_processed_token = pre_process(token)\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        \n",
    "        if not pre_processed_token:\n",
    "            modified_tokens.append(token)\n",
    "            continue\n",
    "\n",
    "        best_emoji = None\n",
    "        best_similarity = 0\n",
    "        \n",
    "        pre_processed_token = pre_processed_token[0]\n",
    "        synonyms = find_synonym_words(pre_processed_token, wn_tag)\n",
    "        for synonum_synset in synonyms:\n",
    "            best_emoji, best_similarity = get_best_matching_emoji(synonum_synset, emoji_dataset, threshold)\n",
    "            if best_emoji:\n",
    "                break\n",
    "\n",
    "        if not best_emoji:\n",
    "            hypernyms = get_hypernyms(pre_processed_token, wn_tag)\n",
    "            for hypernym in hypernyms:\n",
    "                best_emoji, best_similarity = get_best_matching_emoji(hypernym, emoji_dataset, threshold)\n",
    "                if best_emoji:\n",
    "                    break\n",
    "        \n",
    "        if best_emoji:\n",
    "            modified_tokens.append(best_emoji)\n",
    "        else:\n",
    "            modified_tokens.append(token)\n",
    "        \n",
    "        similarities[token] = best_similarity\n",
    "\n",
    "    modified_sentence = \" \".join(modified_tokens)\n",
    "    \n",
    "    return modified_sentence, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_emoji(sentence):\n",
    "    modified_sentence, _ = replace_with_emoji_wordnet(sentence, emojis_dataset)\n",
    "    return modified_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I want pizza and a movie night.\n",
      "Modified Sentence: I want ğŸ• and a ğŸ¥ ğŸŒƒ .\n",
      "Similarities: {'want': 0.3333333333333333, 'pizza': 1.0, 'movie': 1.0, 'night': 1.0}\n",
      "\n",
      "Input: This is such a sad day.\n",
      "Modified Sentence: This is such a ğŸ˜¥ day .\n",
      "Similarities: {'sad': 1.0, 'day': 0.3333333333333333}\n",
      "\n",
      "Input: Happy birthday to you!\n",
      "Modified Sentence: Happy ğŸ‚ to you !\n",
      "Similarities: {'Happy': 0.3333333333333333, 'birthday': 1.0}\n",
      "\n",
      "Input: I need a vacation by the beach.\n",
      "Modified Sentence: I need a vacation by the ğŸ–ï¸ .\n",
      "Similarities: {'need': 0.3333333333333333, 'vacation': 0.25, 'beach': 1.0}\n",
      "\n",
      "Input: coffee\n",
      "Modified Sentence: â˜•\n",
      "Similarities: {'coffee': 1.0}\n",
      "\n",
      "Input: star boy\n",
      "Modified Sentence: âœ¡ï¸ ğŸ‘¦\n",
      "Similarities: {'star': 1.0, 'boy': 1.0}\n",
      "\n",
      "Input: i love you \n",
      "Modified Sentence: i love you\n",
      "Similarities: {'love': 0.3333333333333333}\n",
      "\n",
      "Input: the pizza is great\n",
      "Modified Sentence: the ğŸ• is great\n",
      "Similarities: {'pizza': 1.0, 'great': 0.3333333333333333}\n",
      "\n",
      "Input: chicken lays eggs \n",
      "Modified Sentence: ğŸ” lays ğŸ¥š\n",
      "Similarities: {'chicken': 1.0, 'lays': 0.25, 'eggs': 1.0}\n",
      "\n",
      "Input: i have scored hundred in maths \n",
      "Modified Sentence: i have scored hundred in maths\n",
      "Similarities: {'scored': 0.2, 'hundred': 0, 'maths': 0.2}\n",
      "\n",
      "Input: She is the queen of hearts \n",
      "Modified Sentence: She is the queen of â™¥ï¸\n",
      "Similarities: {'queen': 0.3333333333333333, 'hearts': 1.0}\n",
      "\n",
      "Input: messi is the king of soccer \n",
      "Modified Sentence: messi is the king of âš½\n",
      "Similarities: {'messi': 0, 'king': 0.25, 'soccer': 1.0}\n",
      "\n",
      "Input: lets build a rocket \n",
      "Modified Sentence: lets build a ğŸš€\n",
      "Similarities: {'lets': 0.25, 'build': 0.3333333333333333, 'rocket': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"I want pizza and a movie night.\",\n",
    "    \"This is such a sad day.\",\n",
    "    \"Happy birthday to you!\",\n",
    "    \"I need a vacation by the beach.\",\n",
    "    \"coffee\",\n",
    "    \"star boy\",\n",
    "    \"i love you \",\n",
    "    \"the pizza is great\",\n",
    "    \"chicken lays eggs \",\n",
    "    \"i have scored hundred in maths \",\n",
    "    \"She is the queen of hearts \",\n",
    "    \"messi is the king of soccer \",\n",
    "    \"lets build a rocket \"  \n",
    "]\n",
    "\n",
    "for sent in test_sentences:\n",
    "    modified_sentence, similarity = replace_with_emoji_wordnet(sent, emojis_dataset)\n",
    "    print(f\"Input: {sent}\")\n",
    "    print(f\"Modified Sentence: {modified_sentence}\")\n",
    "    print(f\"Similarities: {similarity}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
